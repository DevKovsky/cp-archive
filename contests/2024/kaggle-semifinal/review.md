# 2024 Kaggle Competition â€” Semifinal Round  
íŒ€ íšŒê³  ë° ê¸°ìˆ  ë¶„ì„

íŒ€ êµ¬ì„±:
- **Benjamin Watson (MIT CS, AI/ML ì§‘ì¤‘ ì „ê³µ)**
- **Timothy Lee (MIT EECS, ì•Œê³ ë¦¬ì¦˜ ì´ë¡  ë° ì‹œìŠ¤í…œ ìµœì í™” ì „ê³µ)**
- **ìµœí™ì—´ (ë°±ì—”ë“œ/AI ì—”ì§€ë‹ˆì–´, ì‹¤ì „ ë¬¸ì œ í•´ê²°í˜• ê°œë°œì)**

---

# ğŸ§© 1. íŒ€ ë°±ê·¸ë¼ìš´ë“œ & ì—­í•  ë¶„ë‹´

ìš°ë¦¬ íŒ€ì˜ ê°•ì ì€ ì„¸ ëª…ì˜ ì—­ëŸ‰ì´ **ì„œë¡œ ë‹¤ë¥¸ ì „ë¬¸ ë¶„ì•¼ë¥¼ ë³´ì™„**í•œë‹¤ëŠ” ì ì´ë‹¤.

### â­ Benjamin  
- MIT CS ì¶œì‹ , **ìˆ˜í•™ì  ëª¨ë¸ë§Â·í†µê³„Â·ML ì•Œê³ ë¦¬ì¦˜ì— ì´ë¡ ì  ê¸°ë°˜ì´ ê°€ì¥ íƒ„íƒ„í•¨**  
- Kaggle ìŠ¤íƒ€ì¼ì˜ feature engineeringê³¼ validation loop ì„¤ê³„ì— íƒì›”  
- íŒŒìƒë³€ìˆ˜(feature) ìƒì„± ì‹œ â€œì™œ ì´ ë³€ìˆ˜ê°€ íš¨ê³¼ì ì¸ì§€â€ë¥¼ ìˆ˜ì‹í™”í•˜ì—¬ ì„¤ëª…í•¨  
- ì½”ë“œ ìŠ¤íƒ€ì¼ì€ functional, reproducible, modular

### â­ Timothy  
- MIT EECS ì¶œì‹ , **ì‹œìŠ¤í…œ ë ˆë²¨ ìµœì í™”Â·C++ êµ¬í˜„ë ¥Â·ì•Œê³ ë¦¬ì¦˜ ì•ˆì •ì„±**ì´ ë§¤ìš° ë†’ìŒ  
- ë©”ëª¨ë¦¬ ì—‘ì„¸ìŠ¤/ìºì‹œ ìµœì í™”ë‚˜ O(NÂ²) â†’ O(N log N)ìœ¼ë¡œ ì¤„ì´ëŠ” ê°ê°ì´ íƒì›”  
- ì‹¤í—˜ í™˜ê²½ ì„¸íŒ…ê³¼ ë³‘ë ¬ ì²˜ë¦¬(ë©€í‹°ìŠ¤ë ˆë”©)ì—ì„œ ê°€ì¥ ê°•í•¨  
- Python/C++ í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì¡°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë§Œë“¦

### â­ Hongyeol   
- íŒ€ì˜ ë°±ì—”ë“œ/AI ì—”ì§€ë‹ˆì–´ë§ ê¸°ë°˜ êµ¬í˜„ë‹´ë‹¹  
- ì‹¤ì „ í”„ë¡œì íŠ¸ë‚˜ ëŒ€ê·œëª¨ ëª¨ë¸ ì„œë¹™ì—ì„œ ì•ˆì •ì   
- ë‘ MIT ì¶œì‹  íŒ€ì›ì˜ **ì´ë¡ ì Â·ìµœì í™” ê´€ì ì„ ì‹¤ì „ ì½”ë“œë¡œ ë…¹ì—¬ë‚´ëŠ” ì—­í• **  
- ë‹¨ìˆœ êµ¬í˜„ì´ ì•„ë‹ˆë¼ â€œì´ê²Œ í”„ë¡œë•ì…˜ì— ë“¤ì–´ê°„ë‹¤ë©´ ë¬¸ì œëŠ” ë­ê³ , ì–´ë–»ê²Œ ê²¬ê³ í•˜ê²Œ ë§Œë“¤ì§€?â€ë¥¼ ê³ ë¯¼í•˜ëŠ” ì‹œê°ì´ ê°•ì 

ì´ ì¡°í•© ë•ë¶„ì— 2024 Kaggle Semifinalì—ì„œëŠ”  
**ML + ìˆ˜í•™ + ìµœì í™” + ì•ˆì • êµ¬í˜„**ì˜ ì™„ë²½í•œ ë°¸ëŸ°ìŠ¤ë¥¼ ë§ì¶œ ìˆ˜ ìˆì—ˆë‹¤.

**ì„¸ ëª…ì˜ ì—­ëŸ‰ ë°©í–¥ì´ ì„œë¡œ ë‹¤ë¥´ë©´ì„œë„ ì‹œë„ˆì§€ê°€ ë†’ì•˜ë‹¤.**

---

# ğŸ§  2. ëŒ€íšŒ ì „ëµ ê°œìš”

Semifinalì—ì„œëŠ”  
- ëŒ€ê·œëª¨ feature set  
- memory limit  
- latency ì œí•œ  
- ëª¨ë¸ inference ìµœì í™”  
ì´ ëª¨ë‘ ì¤‘ìš”í•œ ìš”ì†Œì˜€ë‹¤.

ìš°ë¦¬ íŒ€ì˜ ì „ëµì€ ì•„ë˜ ë‹¨ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–ˆë‹¤:

1) **Baseline feature set ì •ë¦¬**  
2) **Feature groupë³„ cost-performance ratio ê³„ì‚°**  
3) **Greedy + DP ê¸°ë°˜ feature pruning**  
4) **Pseudo-labeling ì¼ë¶€ ì ìš©**  
5) **Outlier injection ë°©ì–´ ì²˜ë¦¬**  
6) **ìµœì¢… inference íŒŒì´í”„ë¼ì¸ ìµœì í™”**

ì´ ì¤‘ ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„ëŠ” (2)~(3)ì—ì„œ ì´ë£¨ì–´ì§„ **feature subset optimization**ì´ì—ˆê³ ,  
ì—¬ê¸°ì„œ ì„¸ ëª…ì˜ í˜‘ì—…ì´ ê°€ì¥ ë¹›ë‚¬ë‹¤.

---

# ğŸ§ª 3. ê¸°ìˆ ì  í•µì‹¬ & ì½”ë“œ ìŠ¤ë‹ˆí«

Semifinalì—ì„œ ì‹¤ì œë¡œ í™œìš©ëœ ëŒ€í‘œì  êµ¬ì¡°ë¥¼ ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.


ğŸ“Œ (1) Feature ê·¸ë£¹ë³„ íš¨ìœ¨ì„± ê³„ì‚° (Benjamin ì„¤ê³„)

```python
score_gain = model_score(feature_set_with_f) - base_score
cost_penalty = time_cost[f]
ratio = score_gain / cost_penalty

Benjaminì´ ratio ê¸°ë°˜ ì •ë ¬ ëŒ€ì‹ 
â€œthreshold-freeâ€ ë°©ì‹ì¸ Pareto frontier pruningì„ ì œì•ˆí•˜ì—¬
feature noiseë¥¼ í¬ê²Œ ì¤„ì¼ ìˆ˜ ìˆì—ˆë‹¤.

ğŸ“Œ (2) Feature ì„ íƒ ìµœì í™” (Timothy C++ ê¸°ë°˜ êµ¬í˜„)

TimothyëŠ” feature costê°€ í´ ë•Œ DP ìµœì í™”ë¥¼ ì•„ë˜ì²˜ëŸ¼ ì••ì¶•í–ˆë‹¤:

for (int c = B; c >= cost[i]; --c) {
    dp[c] = max(dp[c], dp[c - cost[i]] + score[i]);
}


Benjaminì´ ê³„ì‚°í•œ ratio ì •ë³´ë¥¼ hintë¡œ í™œìš©í•˜ì—¬
DPì˜ pruning branchë¥¼ ì ê·¹ì ìœ¼ë¡œ ì¤„ì—¬
ì‹¤ì œë¡œ 30~40%ì˜ ì‹œê°„ ì ˆì•½ íš¨ê³¼ê°€ ìˆì—ˆë‹¤.

ğŸ“Œ (3) ì•ˆì •ì  íŒŒì´í”„ë¼ì¸ êµ¬ì„± (Hongyeol êµ¬í˜„)

ë‚˜ëŠ” ëª¨ë“  feature ê³„ì‚° ë£¨í‹´ì„
production-readyí•œ êµ¬ì¡°ë¡œ ë¦¬íŒ©í† ë§í–ˆë‹¤:

Null Handling

Outlier clipping

Logging / Debug flag

Batch pre-allocation

Multi-thread safe preprocessing pipeline

ì˜ˆ:

def safe_normalize(x, mean, std):
    if std < 1e-6:
        return 0.0
    return (x - mean) / std

â€œì‹¤ì œ ì„œë¹„ìŠ¤ ë ˆë²¨ì—ì„œëŠ” ì´ê²Œ í•„ìˆ˜ì â€ì´ë¼ê³  ì¸ì •í•œ ë¶€ë¶„ì´ì—ˆë‹¤.

ğŸ† 4. ì˜í•œ ì 
1) ì „ë¬¸ì„±ì´ ë‹¤ë¥´ê²Œ ë¶„í¬í•œ íŒ€ì˜ ê°•ì ì´ ê·¹ëŒ€í™”ë¨

Benjamin: ì´ë¡ /ìˆ˜í•™

Timothy: ìµœì í™”/ì„±ëŠ¥

í™ì—´: ì•ˆì • êµ¬í˜„/ì—”ì§€ë‹ˆì–´ë§

ê°ì ì—­í• ì´ ê²¹ì¹˜ì§€ ì•Šê³  â€œí•©ì³ì•¼ë§Œ ì™„ì„±ë˜ëŠ” êµ¬ì¡°â€ì˜€ë‹¤.

2) ëª¨ë¸ ê²€ì¦ ë£¨í”„ êµ¬ì¡°ê°€ ë§¤ìš° ì•ˆì •ì ì´ì—ˆë‹¤

Benjaminì˜ cross-validation ì„¤ê³„ëŠ” ì™„ì„±ë„ê°€ ë§¤ìš° ë†’ì•˜ê³ ,
í™ì—´ì˜ êµ¬í˜„ì´ ì‹¤ì œ ì½”ë“œë¡œ ì•ˆì •ì ìœ¼ë¡œ ë…¹ì•„ë“¤ì—ˆë‹¤.

3) Feature selectionì—ì„œ noiseë¥¼ í¬ê²Œ ì¤„ì¸ ê²ƒì´ ì„±ê³µì˜ í•µì‹¬

â€œë§ì€ featureë¥¼ ì“´ë‹¤ê³  ì„±ëŠ¥ì´ ì˜¤ë¥´ì§€ ì•ŠëŠ”ë‹¤â€ëŠ”
Kaggleì˜ ë³¸ì§ˆì„ ì •í™•íˆ ì´í•´í•œ ì „ëµì´ì—ˆë‹¤.

âš ï¸ 5. ê°œì„ í•  ì 
1) ë‚˜ì˜ ìˆ˜í•™ì  ëª¨ë¸ë§ ì†ë„ë¥¼ ì¡°ê¸ˆ ë” ëŒì–´ì˜¬ë¦´ í•„ìš”ê°€ ìˆìŒ

ì—´ë“±ê°ì´ ì•„ë‹ˆë¼ ë°©í–¥ì„± ë¬¸ì œ.
ë‘ MIT ì¹œêµ¬ë“¤ì€ ë¬¸ì œë¥¼ ìˆ˜ì‹í™”í•˜ëŠ” ì†ë„ê°€ ë¹ ë¥´ê¸° ë•Œë¬¸ì—
ë‚˜ë„ í•´ë‹¹ ì˜ì—­ì—ì„œ â€œíŒ¨í„´í™”ëœ ì ‘ê·¼ë²•â€ì„ êµ¬ì¶•í•˜ë©´
ì „ì²´ íŒ€ íš¨ìœ¨ì´ ë”ìš± ì˜¬ë¼ê°ˆ ê²ƒì„.

2) ë³‘ë ¬ ì²˜ë¦¬ íŠœë‹ì€ Timothy ì˜ì¡´ë„ê°€ ë§¤ìš° ë†’ìŒ

ë‚´ê°€ C++ ìµœì í™”ì™€ ìºì‹± êµ¬ì¡°ë¥¼ ë” ë°°ìš°ë©´,
íŒ€ ì „ì²´ì˜ ì²˜ë¦¬ëŸ‰ì´ ë‘ ë°°ë¡œ ë›¸ ìˆ˜ ìˆë‹¤.